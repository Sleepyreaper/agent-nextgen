# NextGen Multi-Agent Student Evaluation System

> **Version 1.0.33** Â· Production-ready AI evaluation pipeline with 15+ Disney-themed agents, 4-tier model architecture, and enterprise security via Azure Front Door + WAF.

An intelligent multi-agent system that evaluates high school internship applications using specialized Disney-themed agents coordinated in a 9-step workflow. Built on Azure AI Foundry with comprehensive audit trails, fairness-aware assessment, and school context enrichment.

---

## ğŸ¯ Features

- **9-Step Intelligent Workflow** â€” Orchestrated evaluation: Extract â†’ Match â†’ Enrich â†’ Validate â†’ Evaluate â†’ Synthesize â†’ Report
- **15+ Specialized Agents** â€” Disney-themed AI agents each handling a focused evaluation aspect
- **4-Tier Model Architecture** â€” Premium, Merlin, Workhorse, and Lightweight tiers for cost/quality optimization
- **Smart Student Matching** â€” Composite key matching (name + school + state) prevents duplicates
- **School Context Enrichment** â€” NAVEEN + MOANA bidirectional validation loop for fair assessment
- **Contextual Rigor Weighting** â€” RAPUNZEL calculates academic rigor adjusted by school opportunity (0â€“5 scale)
- **Video Application Support** â€” MIRABEL analyzes video submissions with chunked upload (100KB for WAF compatibility)
- **Interactive Q&A** â€” ARIEL answers natural language questions about any evaluated student
- **Historical Score Import** â€” Upload XLSX scoring spreadsheets and link to training applications
- **XLSX Resolution UI** â€” Search and link unmatched historical scores to training records
- **Comprehensive Audit Trail** â€” 14 interaction types logged to database for compliance
- **Feedback System** â€” User-submitted issues auto-create GitHub issues
- **Telemetry & Observability** â€” OpenTelemetry + Application Insights for agent performance monitoring
- **Azure Front Door + WAF** â€” Enterprise DDoS protection, SSL termination, and bot management
- **Secure by Default** â€” Azure Key Vault credentials, no plaintext secrets, managed identity

---

## ğŸ¦¸ Disney Agent Team

### 9-Step Workflow

```
1ï¸âƒ£  BELLE (Document Analyzer)
    â”‚  Extracts structured data from PDF, DOCX, TXT, MP4
    â”‚
2ï¸âƒ£  Student Matching
    â”‚  Composite key lookup prevents duplicates
    â”‚
2ï¸âƒ£â• High School Pre-Enrichment
    â”‚  Proactively validates/enriches school data
    â”‚
3ï¸âƒ£  NAVEEN (School Data Scientist)
    â”‚  Enriches school context (AP courses, demographics, opportunity score)
    â”‚
3ï¸âƒ£â• School Validation Loop (MOANA â†” NAVEEN)
    â”‚  Bidirectional validation with up to 2 remediation attempts
    â”‚
4ï¸âƒ£  Core Agents (parallel, with per-agent validation gates):
    â”œâ”€ TIANA (Application Reader)
    â”œâ”€ RAPUNZEL (Grade Reader with contextual rigor weighting)
    â”œâ”€ MOANA (School Context & Fairness Weighting)
    â””â”€ MULAN (Recommendation Reader)
    â”‚
5ï¸âƒ£  MILO (Data Scientist)
    â”‚  Pattern analysis against training data
    â”‚
6ï¸âƒ£  MERLIN (Student Evaluator)
    â”‚  Synthesizes all results into comprehensive assessment
    â”‚
7ï¸âƒ£  AURORA (Results Formatter)
    â””â”€ Generates executive summary and evaluation report
```

### All Agents

| Agent | File | Role | Model Tier |
|-------|------|------|------------|
| ğŸ“– **BELLE** | `belle_document_analyzer.py` | Document extraction (PDF, DOCX, TXT, MP4) | Lightweight |
| ğŸ‘¸ **TIANA** | `tiana_application_reader.py` | Application essay & communication analysis | Workhorse |
| ğŸ‘‘ **RAPUNZEL** | `rapunzel_grade_reader.py` | Academic rigor with contextual weighting (0â€“5) | Premium |
| ğŸŒŠ **MOANA** | `moana_school_context.py` | School validation & fairness-aware weighting | Workhorse |
| ğŸ¥‹ **MULAN** | `mulan_recommendation_reader.py` | Recommendation letter synthesis | Workhorse |
| ğŸ“Š **MILO** | `milo_data_scientist.py` | Training data insights & pattern detection | Premium |
| ğŸ§‘â€ğŸ”¬ **NAVEEN** | `naveen_school_data_scientist.py` | School enrichment & demographic research | Workhorse |
| ğŸ§™ **MERLIN** | `merlin_student_evaluator.py` | Overall recommendation & rationale synthesis | Merlin |
| âœ¨ **AURORA** | `aurora_agent.py` | Executive summary & report formatting | Workhorse |
| ğŸ¬ **MIRABEL** | `mirabel_video_analyzer.py` | Video application analysis (frame extraction) | Vision (gpt-4o) |
| ğŸ§œ **ARIEL** | `ariel_qa_agent.py` | Interactive Q&A about evaluated students | Workhorse |
| âš”ï¸ **GASTON** | `gaston_evaluator.py` | Evaluation validation & quality checks | Workhorse |
| ğŸš **BASHFUL** | `bashful_agent.py` | Supporting classification tasks | Lightweight |
| ğŸ§š **FAIRY GODMOTHER** | `fairy_godmother_document_generator.py` | Document generation | Workhorse |
| ğŸ“‹ **FEEDBACK TRIAGE** | `feedback_triage_agent.py` | User feedback classification & GitHub issue creation | Workhorse |

**Orchestrator:** **SMEE** (`smee_orchestrator.py`) â€” Coordinates the full 9-step pipeline.

---

## ğŸ—ï¸ 4-Tier Model Architecture

Models are configured in `src/config.py` and overridable via Key Vault or environment variables:

| Tier | Deployment Name | Base Model | Used By | Env Var |
|------|----------------|------------|---------|---------|
| **Premium** | `gpt-4.1` | GPT-4.1 | Rapunzel, Milo (complex reasoning) | `MODEL_TIER_PREMIUM` |
| **Merlin** | `MerlinGPT5Mini` | GPT-5-mini | Merlin (final evaluation) | `MODEL_TIER_MERLIN` |
| **Workhorse** | `WorkForce4.1mini` | GPT-4.1-mini | Tiana, Mulan, Moana, Gaston, Smee, Naveen, Ariel, Aurora | `MODEL_TIER_WORKHORSE` |
| **Lightweight** | `LightWork5Nano` | GPT-5-nano | Belle, Bashful (classification/triage) | `MODEL_TIER_LIGHTWEIGHT` |
| **Vision** | `gpt-4o` | GPT-4o | Mirabel (video analysis) | â€” |

Additional deployment: `text-embedding-ada-002` for embeddings.

---

## ğŸŒ Web Interface â€” All Pages

The application provides a full-featured web UI built with Flask and Jinja2 templates.

### Navigation Menu (8 pages)

| Nav Item | Route | Description |
|----------|-------|-------------|
| ğŸ“Š Dashboard | `/` | Home page showing pending/evaluated/total counts and recent applications |
| ğŸ‘¥ 2026 Applicants | `/students` | Searchable list of all 2026 applicants sorted by last name with status badges |
| ğŸ§ª Test Data | `/test-data` | Students created via Quick Test for development and testing |
| ğŸ“š Training | `/training` | Historical training applications with upload, import scores, XLSX resolution, and Milo insights |
| ğŸ—„ï¸ Data Management | `/data-management` | Central hub for schools, training data, and database operations |
| ğŸ“¤ Upload Application | `/upload` | Upload student documents (PDF, DOCX, TXT, MP4) to trigger the evaluation pipeline |
| ğŸ“ Feedback | `/feedback` | Report issues or request features â€” auto-creates GitHub issues |
| âš¡ Quick Test | `/test` | Real-time 9-step pipeline test with live agent progress tracking |

### Additional Pages (not in nav)

| Page | Route | Description |
|------|-------|-------------|
| Student Detail | `/student/<id>` | Full student dashboard with score cards and all agent results (Merlin, Aurora, Tiana, Rapunzel, Mulan, Moana) |
| Application Detail | `/application/<id>` | Comprehensive evaluation view with executive summary, agent evaluations, audit trail, and ARIEL Q&A |
| Import Historical Scores | `/import-scores` | Upload XLSX scoring spreadsheets for Milo calibration data |
| School Management | `/schools` | School database with filters, batch enrichment (Naveen + Moana), add/edit schools |
| School Enrichment Detail | `/schools/<id>` | Individual school's demographics, resources, and opportunity scores |
| Process Student | `/process/<id>` | Real-time processing view showing agent progress during evaluation |
| Telemetry Dashboard | `/telemetry` | Agent performance metrics, Application Insights status, school pipeline status |
| Agent Monitor | `/agent-monitor` | Standalone dark-terminal UI for real-time agent debugging |
| Feedback Admin | `/feedback/admin` | Admin view of all user feedback with GitHub issue tracking |
| Test Detail | `/test/<id>` | Individual test run details |

---

## ğŸ—ï¸ Azure Architecture

### Production Infrastructure

| Component | Resource | Details |
|-----------|----------|---------|
| **Azure Front Door** | `nextgen-frontdoor` (Premium) | DDoS protection, SSL termination, global load balancing |
| **WAF Policy** | `nextgenWAFPolicy` | Prevention mode, DRS 2.1, BotManager 1.1, 128KB body inspection |
| **Web App** | `nextgen-agents-web` | Python 3.9 on Linux App Service with staging slot |
| **AI Foundry** | `nextgenagentfoundry` (West US 3) | 7 model deployments across 4 tiers |
| **PostgreSQL** | Flexible Server | Application data, audit trails, training records |
| **Key Vault** | Secure credential store | All secrets managed via Azure AD / Managed Identity |
| **Blob Storage** | Document storage | Student uploads with managed identity access |
| **Application Insights** | Telemetry | Agent performance, token usage, request tracing |

### Endpoints

| Environment | URL |
|-------------|-----|
| **Production** | `https://nextgen-app-h7hvaybqd4grd0b2.b02.azurefd.net` |
| **Staging** | `https://nextgen-staging-acfvbrd4g2cud9cs.b02.azurefd.net` |

### Security Architecture (7 Phases â€” All Complete)

1. **Key Vault Integration** â€” All credentials stored in Azure Key Vault
2. **Managed Identity** â€” App authenticates via Azure AD, no API keys in code
3. **Network Security** â€” SCM basic auth disabled, access restricted to Front Door
4. **Front Door + WAF** â€” Enterprise edge security with bot protection
5. **Audit Logging** â€” 14 interaction types for compliance verification
6. **Storage Security** â€” Blob access via managed identity with RBAC
7. **Deployment Security** â€” ARM-based zip deploy, SCM lock/unlock pattern

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Azure CLI (`az login`)
- Azure subscription with Key Vault + OpenAI access

### Setup

```bash
# Clone and navigate
cd "Agent NextGen"

# Activate virtual environment
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Authenticate with Azure
az login

# Initialize database
python scripts/init/init_database.py

# Start the application
python app.py
```

### Local URLs

| Page | URL |
|------|-----|
| Dashboard | http://localhost:5001 |
| Upload | http://localhost:5001/upload |
| Students | http://localhost:5001/students |
| Test System | http://localhost:5001/test |
| Training | http://localhost:5001/training |
| Schools | http://localhost:5001/schools |

### Configuration

**Primary (Production):** Azure Key Vault â€” secrets retrieved via `DefaultAzureCredential`.

```bash
# One-time setup
./scripts/setup/keyvault_setup.sh
```

**Fallback (Development only):** `.env.local` file for offline development.

```bash
cp .env.example .env.local
nano .env.local  # Add your credentials (never commit this file)
```

---

## ğŸŒ Environment Variables

### Azure OpenAI
| Variable | Description |
|----------|-------------|
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI API endpoint |
| `AZURE_OPENAI_API_KEY` | API key (or use managed identity) |
| `AZURE_OPENAI_DEPLOYMENT_NAME` | Default model deployment name |
| `AZURE_OPENAI_API_VERSION` | API version (e.g., `2024-12-01-preview`) |

### Model Tiers
| Variable | Description | Default |
|----------|-------------|---------|
| `MODEL_TIER_PREMIUM` | Complex reasoning (Rapunzel, Milo) | `gpt-4.1` |
| `MODEL_TIER_MERLIN` | Final evaluation (Merlin) | `MerlinGPT5Mini` |
| `MODEL_TIER_WORKHORSE` | Structured extraction (most agents) | `WorkForce4.1mini` |
| `MODEL_TIER_LIGHTWEIGHT` | Classification/triage (Belle, Bashful) | `LightWork5Nano` |

### PostgreSQL
| Variable | Description |
|----------|-------------|
| `POSTGRES_HOST` | Database server hostname |
| `POSTGRES_PORT` | Port (default: 5432) |
| `POSTGRES_DATABASE` | Database name (`ApplicationsDB`) |
| `POSTGRES_USERNAME` | Connection username |
| `POSTGRES_PASSWORD` | Connection password |

### Application
| Variable | Description |
|----------|-------------|
| `FLASK_SECRET_KEY` | Session management secret |
| `FLASK_ENV` | `development` or `production` |
| `APPLICATIONINSIGHTS_CONNECTION_STRING` | Application Insights telemetry |
| `NEXTGEN_CAPTURE_PROMPTS` | Enable/disable prompt logging (`true`/`false`) |

---

## ğŸ“Š Database Schema

### Core Tables

| Table | Purpose |
|-------|---------|
| `applications` | Student applications with demographics, documents, status |
| `student_school_context` | School enrichment data (AP courses, demographics, opportunity scores) |
| `rapunzel_grades` | Academic data with contextual rigor weighting (0â€“5 scale) |
| `ai_evaluations` | Agent outputs from all 9 workflow steps |
| `agent_results` | Structured agent evaluation results |
| `historical_scores` | Imported XLSX scoring data for Milo calibration |

### Audit & Compliance Tables

| Table | Purpose |
|-------|---------|
| `agent_interactions` | 14 interaction types covering the full 9-step workflow (JSONB output, timestamps) |
| `file_upload_audit` | AI-based student matching decisions with confidence scores and human review fields |

---

## ğŸ¤– The 9-Step Workflow in Detail

### Step 1 â€” BELLE Extraction
Upload triggers BELLE to extract structured data (name, school, grades, test scores, achievements) from any supported document format.

### Step 2 â€” Smart Student Matching
Composite key lookup: `first_name + last_name + high_school + state_code`. Matches existing student or creates new record. Prevents duplicates while enabling re-evaluation with additional files.

### Step 2+ â€” High School Pre-Enrichment
Validates school record exists. If missing, NAVEEN proactively enriches before the validation loop begins.

### Step 3 â€” School Enrichment (NAVEEN)
Enriches school record with AP course counts, honors programs, community opportunity score (0â€“100), free/reduced lunch %, enrollment, and demographics.

### Step 3+ â€” School Validation Loop (MOANA â†” NAVEEN)
MOANA validates school against 7 required fields. On failure, NAVEEN remediates (up to 2 attempts). Outcome: school meets requirements or workflow pauses for additional data.

### Step 4 â€” Core Agent Evaluation (Parallel)
Four agents run simultaneously with per-agent validation gates:
1. **TIANA** â€” Application essays and communication
2. **RAPUNZEL** â€” Grades with contextual rigor (base rigor Ã— AP availability Ã— opportunity score)
3. **MOANA** â€” School context and fairness factor
4. **MULAN** â€” Recommendation letter synthesis

### Step 5 â€” Pattern Analysis (MILO)
Analyzes performance against training data. Identifies selection indicators and historical patterns.

### Step 6 â€” Comprehensive Evaluation (MERLIN)
Synthesizes all agent outputs, applies fairness adjustments, produces overall score and recommendation with strengths/considerations.

### Step 7 â€” Results Formatting (AURORA)
Generates executive summary and formatted evaluation report for human review.

---

## ğŸ“¤ File Upload & Re-Evaluation

### Supported Formats
PDF, DOCX, DOC, TXT, MP4 (video with chunked upload at 100KB for WAF compatibility)

### Upload Types
- **2026 Applicant** â€” Real admissions: full 9-step pipeline
- **Training Data** â€” Historical examples for Milo calibration
- **Test Upload** â€” Isolated test environment, clearable without affecting real data

### Re-Evaluation
When a student already exists, new files are added to the same record and the full 9-step workflow re-runs with all available documents. More data = more accurate assessment.

### Status Badges
- ğŸ“‹ **Pending** â€” Waiting for evaluation
- ğŸ”„ **Processing** â€” Workflow in progress
- âœ… **Complete** â€” All steps finished
- âš ï¸ **Waiting** â€” Additional documents needed

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                              # Flask web application (~7000 lines)
â”œâ”€â”€ main.py                             # CLI interface
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ VERSION                             # Current version (1.0.33)
â”œâ”€â”€ Dockerfile                          # Container configuration
â”œâ”€â”€ Procfile                            # Process configuration
â”œâ”€â”€ startup.sh / startup.py             # App Service startup
â”œâ”€â”€ wsgi.py                             # WSGI entry point
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema_postgresql.sql           # Core PostgreSQL schema
â”‚   â”œâ”€â”€ schema_school_enrichment.sql    # School context tables
â”‚   â”œâ”€â”€ schema_azure_sql.sql            # Azure SQL variant
â”‚   â””â”€â”€ *.sql                           # Migration scripts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                       # Configuration (Key Vault + env vars + 4-tier models)
â”‚   â”œâ”€â”€ database.py                     # PostgreSQL operations + audit logging
â”‚   â”œâ”€â”€ logger.py                       # Logging utilities
â”‚   â”œâ”€â”€ storage.py                      # Blob storage operations
â”‚   â”œâ”€â”€ test_data_generator.py          # Synthetic test data generation
â”‚   â”œâ”€â”€ file_upload_handler.py          # AI-based student matching & upload orchestration
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ smee_orchestrator.py        # 9-step workflow orchestrator
â”‚       â”œâ”€â”€ belle_document_analyzer.py  # Step 1: Document extraction
â”‚       â”œâ”€â”€ naveen_school_data_scientist.py  # Step 3: School enrichment
â”‚       â”œâ”€â”€ moana_school_context.py     # Step 3+: School validation & fairness
â”‚       â”œâ”€â”€ tiana_application_reader.py # Step 4: Application analysis
â”‚       â”œâ”€â”€ rapunzel_grade_reader.py    # Step 4: Grade analysis + rigor weighting
â”‚       â”œâ”€â”€ mulan_recommendation_reader.py   # Step 4: Recommendation synthesis
â”‚       â”œâ”€â”€ milo_data_scientist.py      # Step 5: Pattern analysis
â”‚       â”œâ”€â”€ merlin_student_evaluator.py # Step 6: Overall evaluation
â”‚       â”œâ”€â”€ aurora_agent.py             # Step 7: Report formatting
â”‚       â”œâ”€â”€ mirabel_video_analyzer.py   # Video application analysis
â”‚       â”œâ”€â”€ ariel_qa_agent.py           # Interactive Q&A
â”‚       â”œâ”€â”€ ariel_adapter.py            # Ariel adapter layer
â”‚       â”œâ”€â”€ gaston_evaluator.py         # Evaluation validation
â”‚       â”œâ”€â”€ bashful_agent.py            # Classification support
â”‚       â”œâ”€â”€ fairy_godmother_document_generator.py  # Document generation
â”‚       â”œâ”€â”€ feedback_triage_agent.py    # Feedback â†’ GitHub issues
â”‚       â”œâ”€â”€ agent_monitor.py            # Real-time agent monitoring
â”‚       â”œâ”€â”€ agent_requirements.py       # Agent validation gates
â”‚       â”œâ”€â”€ foundry_client.py           # Azure AI Foundry client
â”‚       â”œâ”€â”€ telemetry_helpers.py        # OpenTelemetry integration
â”‚       â”œâ”€â”€ system_prompts.py           # Shared agent prompts
â”‚       â””â”€â”€ base_agent.py              # Base agent class
â”œâ”€â”€ web/
â”‚   â””â”€â”€ templates/                      # 22 Jinja2 HTML templates
â”‚       â”œâ”€â”€ base.html                   # Shared layout with nav menu
â”‚       â”œâ”€â”€ index.html                  # Dashboard
â”‚       â”œâ”€â”€ students.html               # 2026 Applicants list
â”‚       â”œâ”€â”€ student_detail.html         # Individual student dashboard
â”‚       â”œâ”€â”€ application.html            # Full evaluation detail + ARIEL Q&A
â”‚       â”œâ”€â”€ upload.html                 # File upload (PDF/DOCX/TXT/MP4)
â”‚       â”œâ”€â”€ training.html               # Training data management
â”‚       â”œâ”€â”€ test.html                   # Real-time pipeline test
â”‚       â”œâ”€â”€ test_data.html              # Test data students
â”‚       â”œâ”€â”€ test_detail.html            # Individual test detail
â”‚       â”œâ”€â”€ import_scores.html          # XLSX historical score import
â”‚       â”œâ”€â”€ school_management.html      # School database management
â”‚       â”œâ”€â”€ school_enrichment_detail.html  # Individual school detail
â”‚       â”œâ”€â”€ data_management.html        # Central data management hub
â”‚       â”œâ”€â”€ process_student.html        # Live processing progress
â”‚       â”œâ”€â”€ feedback.html               # User feedback form
â”‚       â”œâ”€â”€ feedback_admin.html         # Feedback admin panel
â”‚       â”œâ”€â”€ telemetry_dashboard.html    # Telemetry & observability
â”‚       â”œâ”€â”€ agent_monitor.html          # Agent debugging terminal
â”‚       â”œâ”€â”€ student_summary_json.html   # Student summary JSON view
â”‚       â”œâ”€â”€ _student_list.html          # Reusable student list component
â”‚       â””â”€â”€ debug_dataset.html          # Debug dataset viewer
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/                          # Setup and provisioning scripts
â”‚   â”œâ”€â”€ init/                           # Database initialization
â”‚   â”œâ”€â”€ migrate/                        # Database migrations
â”‚   â”œâ”€â”€ verify/                         # Verification scripts
â”‚   â”œâ”€â”€ audit/                          # Audit scripts
â”‚   â”œâ”€â”€ check/                          # Health checks
â”‚   â”œâ”€â”€ fix/                            # Fix scripts
â”‚   â”œâ”€â”€ git-hooks/                      # Git hooks
â”‚   â”œâ”€â”€ backfill_summaries.py           # Backfill student summaries
â”‚   â”œâ”€â”€ seed_schools.py                 # Seed school database
â”‚   â””â”€â”€ bump_version.py                 # Version management
â”œâ”€â”€ documents/                          # Documentation
â”‚   â”œâ”€â”€ setup/                          # Setup guides
â”‚   â”œâ”€â”€ deployment/                     # Deployment docs
â”‚   â”œâ”€â”€ security/                       # Security guidelines
â”‚   â”œâ”€â”€ verification/                   # Verification checklists
â”‚   â”œâ”€â”€ debugging/                      # Debug guides
â”‚   â””â”€â”€ migration/                      # Migration docs
â”œâ”€â”€ testing/                            # Test utilities
â”œâ”€â”€ uploads/                            # Temporary upload storage
â”œâ”€â”€ student_documents/                  # Student document storage
â””â”€â”€ logs/                               # Application logs
```

---

## ğŸš¢ Deployment

### Method: ARM-Based Zip Deploy

SCM basic auth is disabled and Azure Front Door is in front of the SCM endpoint. Deployment uses `az webapp deploy --type zip` which goes through the ARM management plane.

### Deployment Pattern

```bash
# 1. Create deployment zip (excludes dev files)
zip -r /tmp/nextgen-deploy.zip . \
  -x '.git/*' '.venv/*' '__pycache__/*' '*/__pycache__/*' \
     '*.pyc' '.env' '.env.*' 'node_modules/*' 'logs/*' \
     '.DS_Store' 'student_documents/*' 'uploads/*' 'testing/*'

# 2. Deploy to Production
# Unlock SCM
az webapp update -g NextGen_Agents -n nextgen-agents-web \
  --set siteConfig.scmIpSecurityRestrictionsUseMain=false
sleep 15

# Deploy
az webapp deploy -g NextGen_Agents -n nextgen-agents-web \
  --src-path /tmp/nextgen-deploy.zip --type zip --async true

# Re-lock SCM
az webapp update -g NextGen_Agents -n nextgen-agents-web \
  --set siteConfig.scmIpSecurityRestrictionsUseMain=true

# 3. Deploy to Staging (same pattern with --slot staging)
az webapp update -g NextGen_Agents -n nextgen-agents-web --slot staging \
  --set siteConfig.scmIpSecurityRestrictionsUseMain=false
sleep 15
az webapp deploy -g NextGen_Agents -n nextgen-agents-web --slot staging \
  --src-path /tmp/nextgen-deploy.zip --type zip --async true
az webapp update -g NextGen_Agents -n nextgen-agents-web --slot staging \
  --set siteConfig.scmIpSecurityRestrictionsUseMain=true
```

### CI/CD

GitHub Actions workflow at `.github/workflows/deploy-to-azure.yml` uses Azure OIDC authentication. Required GitHub Secrets: `AZURE_CLIENT_ID`, `AZURE_TENANT_ID`, `AZURE_SUBSCRIPTION_ID`.

---

## ğŸ§ª Testing

### Real-Time Test System (`/test`)
Run the full 9-step pipeline with live agent progress tracking:
- ğŸš€ **Random Students** â€” Generate synthetic data each run
- âš¡ **Preset Students** â€” Fixed test data (Alice, Brian, Carol)
- âš¡ **Single Student** â€” Quick single-student test
- ğŸ—‘ï¸ **Clear Test Data** â€” Remove all test students

### Test Data Generator
```python
from src.test_data_generator import test_data_generator

# Generate batch
students = test_data_generator.generate_batch(count=5)

# Specific grade levels (realistic birthdates for June 2026)
senior = test_data_generator.generate_student(grade_level=12)   # Born 2007-2008
junior = test_data_generator.generate_student(grade_level=11)   # Born 2008-2009
sophomore = test_data_generator.generate_student(grade_level=10) # Born 2009-2010
```

### Command-Line Testing
```bash
python testing/test_smee.py       # Test orchestrator
python testing/test_agent.py      # Test file upload handler
```

---

## ğŸ” Security

### Zero Plaintext Credentials
- âœ… All secrets in Azure Key Vault with enterprise-grade encryption
- âœ… No `.env` files in Git (`.gitignore` enforced)
- âœ… No hardcoded credentials anywhere in code
- âœ… Managed Identity for Azure service authentication
- âœ… TLS/SSL everywhere via Front Door
- âœ… SCM basic auth disabled â€” deployments use ARM management plane
- âœ… WAF policy in Prevention mode with DRS 2.1 + Bot Manager 1.1
- âœ… Front Door ID validation on App Service (rejects direct access)
- âœ… Audit trail for all operations

### Key Vault Secrets
| Category | Secrets |
|----------|---------|
| PostgreSQL | `postgres-host`, `postgres-port`, `postgres-database`, `postgres-username`, `postgres-password` |
| Azure OpenAI | `azure-openai-endpoint`, `azure-deployment-name`, `azure-api-version` |
| Application | `flask-secret-key` (auto-generated) |
| Azure | `azure-subscription-id`, `azure-resource-group` |

---

## ğŸ“ˆ Observability

### OpenTelemetry Integration
The application uses `azure-monitor-opentelemetry` for automatic instrumentation of Flask, requests, and psycopg2. Agent-level telemetry tracks:
- Token usage per agent per request
- Agent execution duration
- Model deployment utilization
- Error rates and retry counts

### Telemetry Dashboard (`/telemetry`)
Real-time metrics with 30-second auto-refresh: Application Insights connection status, agent performance, and school pipeline status.

### Agent Monitor (`/agent-monitor`)
Standalone terminal-style debugging interface for real-time agent execution monitoring.

---

## ğŸ“š Additional Documentation

### Core
- [WORKFLOW_MAP.md](WORKFLOW_MAP.md) â€” 9-step workflow visualization with data flows
- [README_WORKFLOW.md](README_WORKFLOW.md) â€” User-focused workflow guide
- [AGENT_ARCHITECTURE_DETAILED.md](AGENT_ARCHITECTURE_DETAILED.md) â€” Agent implementation details

### Setup & Configuration
- [documents/setup/SETUP_GUIDE_MANUAL.md](documents/setup/SETUP_GUIDE_MANUAL.md) â€” Manual setup guide
- [documents/setup/KEY_VAULT_SETUP.md](documents/setup/KEY_VAULT_SETUP.md) â€” Key Vault configuration
- [documents/setup/POSTGRESQL_KEYVAULT_SETUP.md](documents/setup/POSTGRESQL_KEYVAULT_SETUP.md) â€” PostgreSQL + Key Vault

### Deployment
- [documents/deployment/AZURE_WEBAPP_DEPLOY.md](documents/deployment/AZURE_WEBAPP_DEPLOY.md) â€” Production deployment guide
- [documents/deployment/DEPLOYMENT_CHECKLIST.md](documents/deployment/DEPLOYMENT_CHECKLIST.md) â€” Pre-deployment verification

### Security
- [documents/security/SECURITY_GUIDE.md](documents/security/SECURITY_GUIDE.md) â€” Security best practices
- [documents/security/SECURITY_AND_EFFICIENCY_AUDIT.md](documents/security/SECURITY_AND_EFFICIENCY_AUDIT.md) â€” Compliance audit

---

## ğŸ› ï¸ Troubleshooting

**Database connection issues:**
- Verify PostgreSQL credentials in Key Vault or `.env.local`
- Test: `python -c "from src.database import Database; db = Database(); print('OK')"`

**AI evaluation errors:**
- Ensure Azure OpenAI resource is accessible
- Check deployment names match tier config in `src/config.py`
- Verify `Cognitive Services OpenAI User` role is assigned

**Key Vault access:**
- Run `az login` to authenticate
- Verify `Reader` + `Key Vault Secrets User` roles
- Check: `az keyvault show --name your-keyvault-name`

**Application Insights not showing data:**
- Ensure `APPLICATIONINSIGHTS_CONNECTION_STRING` is set
- Wait 5â€“10 minutes for telemetry propagation
- Set `NEXTGEN_CAPTURE_PROMPTS=true` for detailed logging

**Video upload fails:**
- Upload uses 100KB chunked transfer (WAF 128KB body limit)
- Check Front Door WAF logs for blocked requests
- Ensure `opencv-python-headless` is installed for Mirabel

---

## ğŸ—ï¸ Architecture Decisions

| Decision | Rationale |
|----------|-----------|
| **9-Step Workflow** | Stages agents by dependency, enables validation gates, supports remediation loops, audit-friendly |
| **Composite Key Matching** | Prevents duplicates, enables re-evaluation, handles multi-school scenarios |
| **Contextual Rigor (RAPUNZEL)** | Fair assessment across school types â€” adjusts for AP/Honors availability and opportunity |
| **Fairness Factor (MOANA)** | Evidence-based bias reduction using public school data, transparent and reviewable |
| **4-Tier Models** | Cost optimization â€” use expensive models only for complex tasks, lightweight for simple extraction |
| **Front Door + WAF** | Enterprise DDoS protection without EasyAuth complexity |
| **ARM Zip Deploy** | Works with SCM basic auth disabled and Front Door blocking SCM |

---

## ğŸ“ License & Support

Requires:
- Azure subscription (OpenAI, Key Vault, PostgreSQL, Front Door)
- GitHub account (CI/CD, feedback issues)
- Python 3.9+

For support, see documentation in the `/documents` directory.
