# Azure AI Foundry Configuration
# ================================
# ðŸ”’ CRITICAL SECURITY NOTICE
# ================================
# This file is a TEMPLATE. Do NOT put real credentials here.
# All secrets should be stored in Azure Key Vault ONLY.
# NEVER commit any .env file with real credentials to git.
# 
# For local development only:
# 1. Copy this file to .env (git-ignored)
# 2. Fill in YOUR ACTUAL VALUES (test credentials only)
# 3. This .env file will NOT be committed
# 4. Verify .gitignore includes ".env"
#
# For production:
# 1. Use Azure Key Vault
# 2. Use Managed Identity (no connection strings)
# 3. Set environment variables in Azure App Service
#
# To configure Key Vault secrets, run: ./setup_keyvault.sh
# See documents/security/REMEDIATION_GUIDE.md for detailed setup

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
AZURE_DEPLOYMENT_NAME=your-deployment-name
AZURE_API_VERSION=2024-12-01-preview

# Azure AI Foundry Project Dataset (required for Milo dataset upload)
# The "PROJECT_ENDPOINT" (aka FOUNDRY_PROJECT_ENDPOINT) should point to your
# Foundry project host.  Historically this used the
# `*.services.ai.azure.com/api/projects/...` pattern, but when calling model
# deployments we now prefer the standard Azure OpenAI/Cognitive Services
# base URL ("*.cognitiveservices.azure.com").  The code will normalize either
# form automatically for chat completion requests, but dataset and other
# project operations still rely on the full path.
# Example of a generic AI endpoint (used for model calls):
#   https://nextgenagentfoundry.cognitiveservices.azure.com
# Example of a full project endpoint (used for dataset operations):
#   https://nextgenagentfoundry.services.ai.azure.com/api/projects/nextgenagents
PROJECT_ENDPOINT=https://your-ai-services-account-name.cognitiveservices.azure.com
FOUNDRY_DATASET_NAME=nextgen-training-dataset
FOUNDRY_DATASET_CONNECTION_NAME=your-foundry-storage-connection

# Foundry Model Configuration
# FOUNDRY_MODEL_NAME overrides the default reasoning model (gpt-4.1-2025-04-14)
# FOUNDRY_VISION_MODEL_NAME selects the vision/OCR model for image-based pages (default: gpt-4o)
# FOUNDRY_WHISPER_MODEL_NAME selects the Whisper model for video audio transcription (optional)
# FOUNDRY_MODEL_NAME=gpt-4.1-2025-04-14
# FOUNDRY_VISION_MODEL_NAME=gpt-4o
# FOUNDRY_WHISPER_MODEL_NAME=whisper

# Mirabel Video Analyzer Settings
# MIRABEL_FRAME_INTERVAL=3.0     # Seconds between frame captures (default: 3)
# MIRABEL_MAX_FRAMES=20          # Maximum frames to extract (default: 20)

# Azure Subscription and Resource Group
AZURE_SUBSCRIPTION_ID=your-subscription-id
AZURE_RESOURCE_GROUP=your-resource-group

# PostgreSQL Database Configuration
# Option 1: Use full connection URL
DATABASE_URL=postgresql://user:password@host:5432/dbname?sslmode=prefer

# Option 2: Use individual components (preferred)
POSTGRES_HOST=your-postgres-host
POSTGRES_PORT=5432
POSTGRES_DB=ApplicationsDB
POSTGRES_USER=your-username
POSTGRES_PASSWORD=your-secure-password

# Content Processing Solution Accelerator
CONTENT_PROCESSING_ENDPOINT=https://your-content-processing-endpoint/api/analyze
CONTENT_PROCESSING_API_KEY=your-content-processing-key
CONTENT_PROCESSING_API_KEY_HEADER=x-api-key
CONTENT_PROCESSING_ENABLED=true

# Flask Configuration
FLASK_SECRET_KEY=your-secure-random-key-run-openssl-rand-hex-32

# App Metadata
APP_VERSION=0.1

# GitHub Feedback Tracking (Key Vault recommended)
GITHUB_API_TOKEN=your-github-token

# ============================================================================
# OpenTelemetry & Application Insights Observability Configuration
# ============================================================================
# 
# RECOMMENDED: Use Azure Application Insights with Azure Monitor OpenTelemetry
#
# Get your connection string from Azure Portal:
# Applications Insights â†’ Overview â†’ Connection String
#
# For production, store in Azure Key Vault, not in .env

# Application Insights Configuration (RECOMMENDED for Azure)
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=your-key;IngestionEndpoint=https://your-region.in.applicationinsights.azure.com/;LiveEndpoint=https://your-region.livediagnostics.monitor.azure.com/;ProfilerEndpoint=https://your-region.profiler.monitor.azure.com/;SnapshotEndpoint=https://your-region.snapshot.monitor.azure.com/

# Alternative: Old-style instrumentation key (if connection string unavailable)
APPINSIGHTS_INSTRUMENTATION_KEY=your-instrumentation-key-here

# ============================================================================
# Standard OpenTelemetry Environment Variables
# ============================================================================
# Used when NOT using Azure Monitor (e.g., local development with Aspire Dashboard)

# Service Identification
OTEL_SERVICE_NAME=agent-framework
OTEL_SERVICE_VERSION=1.0.0

# For Aspire Dashboard or other OTLP-compatible backends
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OTEL_EXPORTER_OTLP_PROTOCOL=grpc
# OTEL_EXPORTER_OTLP_HEADERS=api-key=your-api-key

# ============================================================================
# Telemetry Configuration
# ============================================================================

# Enable OpenTelemetry instrumentation
ENABLE_INSTRUMENTATION=true

# Capture sensitive data (PROMPTS AND RESPONSES) in telemetry
# âš ï¸  WARNING: Set to 'true' ONLY for development/testing
# âš ï¸  Do NOT enable in production - may expose sensitive information
ENABLE_SENSITIVE_DATA=false

# Enable console output for telemetry (for debugging)
# Shows trace, metrics, and log data in stdout for local development
ENABLE_CONSOLE_EXPORTERS=false

# ============================================================================
# Observability Features
# ============================================================================
#
# When properly configured, the following are automatically tracked:
#
# TRACES (via OpenTelemetry spans):
#   - Agent invocation (name, status, duration)
#   - LLM model calls (model, tokens, latency, parameters)
#   - Tool execution (function name, arguments, results)
#   - API calls (endpoint, method, status, duration)
#
# METRICS (via OpenTelemetry meters):
#   - gen_ai.client.operation.duration (histogram) - LLM call duration
#   - gen_ai.client.token.usage (histogram) - Token consumption per call
#   - agent_execution_duration_ms (counter) - Agent processing time
#   - agent_tokens_used (counter) - Total tokens used by agent
#   - agent_execution_status (counter) - Success/failure tracking
#
# LOGS:
#   - Agent execution logs
#   - Errors and exceptions
#   - Performance warnings
#
# ============================================================================
# How to Monitor in Azure Portal
# ============================================================================
#
# 1. Open Application Insights resource in Azure Portal
# 2. Select "Logs" (KQL queries) or "Metrics"
# 3. Query traces and metrics:
#
#    // View agent executions
#    traces | where operation_Name contains "agent_execution"
#
#    // View LLM performance
#    traces | where message contains "model_call"
#
#    // View token usage
#    customMetrics | where name == "gen_ai.client.token.usage"
#
#    // View API latency
#    requests | where duration > 5000
#
# 4. Create alerts on key metrics (e.g., error rate > 5%)
# 5. Set up live metrics for real-time monitoring
#
# ============================================================================
# Local Development: Using Aspire Dashboard
# ============================================================================
#
# To use Aspire Dashboard for local development:
#
# 1. Install Docker and run Aspire:
#    docker run --rm -it -d -p 18888:18888 -p 4317:18889 \
#      --name aspire-dashboard \
#      mcr.microsoft.com/dotnet/aspire-dashboard:latest
#
# 2. Set environment variables:
#    ENABLE_INSTRUMENTATION=true
#    OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
#
# 3. View telemetry at http://localhost:18888
#
# ============================================================================

GITHUB_REPO=Sleepyreaper/agent-nextgen
GITHUB_TOKEN=your-github-token

# Azure Key Vault (required for production)
AZURE_KEY_VAULT_NAME=your-keyvault-name
